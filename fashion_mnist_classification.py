# -*- coding: utf-8 -*-
"""Fashion MNIST Classification.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1_5FuLZCIz2vqFzZP5nDeE0oAHVTarV8L

**Fashion MNIST Classification with CNN in Python**
"""

#Importing Libraries
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.callbacks import EarlyStopping

# Set random seed for reproducibility
np.random.seed(42)
tf.random.set_seed(42)

# Define the class names for Fashion MNIST
class_names = [
    'T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',
    'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot'
]

# Step 1: Load the data
print("Loading data...")
train_data = pd.read_csv('fashion-mnist_train.csv')
test_data = pd.read_csv('fashion-mnist_test.csv')

# Step 2: Prepare the data
X_train = train_data.drop('label', axis=1).values.reshape(-1, 28, 28, 1) / 255.0
y_train = to_categorical(train_data['label'].values, 10)

X_test = test_data.drop('label', axis=1).values.reshape(-1, 28, 28, 1) / 255.0
y_test = to_categorical(test_data['label'].values, 10)

print(f"Training data shape: {X_train.shape}")
print(f"Test data shape: {X_test.shape}")

# Step 3: Build the 6-layer CNN model
print("\nBuilding 6-layer CNN model...")
model = Sequential([
    # Layer 1: Conv + Pooling
    Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(28, 28, 1)),
    MaxPooling2D((2, 2)),

    # Layer 2: Conv + Pooling
    Conv2D(64, (3, 3), activation='relu', padding='same'),
    MaxPooling2D((2, 2)),

    # Layer 3: Conv + Pooling
    Conv2D(128, (3, 3), activation='relu', padding='same'),
    MaxPooling2D((2, 2)),

    # Layer 4: Flatten
    Flatten(),

    # Layer 5: Dense with Dropout
    Dense(128, activation='relu'),
    Dropout(0.5),

    # Layer 6: Output
    Dense(10, activation='softmax')
])

# Compile the model
model.compile(
    optimizer='adam',
    loss='categorical_crossentropy',
    metrics=['accuracy']
)

model.summary()

# Step 4: Train the model
print("\nTraining the model...")
early_stop = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)

history = model.fit(
    X_train, y_train,
    epochs=10,  # Reduced for quicker execution
    batch_size=64,
    validation_split=0.1,
    callbacks=[early_stop],
    verbose=1
)

# Step 5: Evaluate the model
print("\nEvaluating the model...")
test_loss, test_acc = model.evaluate(X_test, y_test, verbose=0)
print(f"Test Accuracy: {test_acc:.4f}")
print(f"Test Loss: {test_loss:.4f}")

# Step 6: Plot training history
plt.figure(figsize=(12, 5))

# Accuracy plot
plt.subplot(1, 2, 1)
plt.plot(history.history['accuracy'], label='Train')
plt.plot(history.history['val_accuracy'], label='Validation')
plt.title('Model Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()

# Loss plot
plt.subplot(1, 2, 2)
plt.plot(history.history['loss'], label='Train')
plt.plot(history.history['val_loss'], label='Validation')
plt.title('Model Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()
plt.tight_layout()
plt.savefig('training_history.png')
plt.show()

# Step 7: Make predictions for at least 2 images
print("\nMaking predictions...")
num_samples = 5  # We'll visualize 5 samples (more than the required 2)

# Select random samples from test set
sample_indices = np.random.choice(len(X_test), num_samples)

plt.figure(figsize=(15, num_samples * 3))
for i, idx in enumerate(sample_indices):
    img = X_test[idx]
    true_label = np.argmax(y_test[idx])

# Make prediction
pred = model.predict(np.expand_dims(img, axis=0), verbose=0)
pred_label = np.argmax(pred)
confidence = np.max(pred)

# Plot image
plt.subplot(num_samples, 2, 2*i+1)
plt.imshow(img.squeeze(), cmap='gray')
plt.title(f"True: {class_names[true_label]}\nPred: {class_names[pred_label]}")
plt.axis('off')

# Plot probabilities
plt.subplot(num_samples, 2, 2*i+2)
plt.barh(class_names, pred[0])
plt.xlabel('Probability')
plt.title(f'Confidence: {confidence:.2f}')
plt.tight_layout()
plt.savefig('predictions.png')
plt.show()

# Step 8: Save the model
model.save('fashion_mnist_cnn.h5')
print("Model saved as 'fashion_mnist_cnn.h5'")

print("\nDone! Check the output files: 'training_history.png' and 'predictions.png'")

